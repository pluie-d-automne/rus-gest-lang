{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G3-oihH2rI-"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "A custom Dataset class must implement three functions: __init__, __len__, and __getitem__.\n",
        "\n",
        "https://github.com/bomri/SlowFast/blob/master/slowfast/datasets/loader.py\n",
        "\n",
        "https://github.com/bomri/SlowFast/blob/master/slowfast/datasets/ava_dataset.py\n",
        "\n",
        "https://github.com/HHTseng/video-classification/blob/master/ResNetCRNN_varylength/UCF101_ResNetCRNN_varlen.py\n",
        "https://www.ai-contentlab.com/2023/01/video-classification-is-important-task.html\n",
        "\n",
        "https://discuss.pytorch.org/t/how-upload-sequence-of-image-on-video-classification/24865/13\n",
        "\n",
        "Оптический поток\n",
        "https://docs.opencv.org/2.4/modules/video/doc/motion_analysis_and_object_tracking.html\n",
        "\n",
        "Skeleton\n",
        "https://www.fireblazeaischool.in/blogs/human-pose-estimation-using-opencv/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader\n",
        "\n",
        "Добавить нормализацию!!!"
      ],
      "metadata": {
        "id": "sL0Mup8ev7iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_list = ['пингвин',\n",
        " 'жираф',\n",
        " 'лягушка',\n",
        " 'бегемот',\n",
        " 'козел',\n",
        " 'лиса',\n",
        " 'динозавр',\n",
        " 'кролик',\n",
        " 'собака',\n",
        " 'обезьяна',\n",
        " 'корова',\n",
        " 'свинья',\n",
        " 'медуза',\n",
        " 'курица',\n",
        " 'павлин',\n",
        " 'дельфин',\n",
        " 'слон',\n",
        " 'медведь',\n",
        " 'лебедь',\n",
        " 'орел',\n",
        " 'бык',\n",
        " 'змея',\n",
        " 'птица',\n",
        " 'лось',\n",
        " 'пчела',\n",
        " 'лев',\n",
        " 'тигр',\n",
        " 'мышь',\n",
        " 'паук',\n",
        " 'бабочка']\n",
        "\n",
        " # Курс Седжвика по алгоритмам"
      ],
      "metadata": {
        "id": "_a8oa_eOWDoS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "RcSpbHhEf-XV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "def load_video(path, begin, end, base_name, resize=(10, 10)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frame_index=begin\n",
        "    i = 0\n",
        "    try:\n",
        "        while True and frame_index <= end:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
        "            frame_name = f'{base_name}_{i}.png'\n",
        "            cv2.imwrite(frame_name, frame)\n",
        "            frame_index+=1\n",
        "            i+=1\n",
        "    finally:\n",
        "        cap.release()\n",
        ""
      ],
      "metadata": {
        "id": "AG_BoaIqf-6V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YV2k0jav3Ygd"
      },
      "outputs": [],
      "source": [
        "annotations_file = \"/content/SLOVO_DF_SHORT.tsv\"\n",
        "video_dir = \"/content/videos\"\n",
        "dataset_dir = \"/content/dataset\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 6\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_labels = pd.read_csv(annotations_file, sep='\\t')\n",
        "video_labels.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FvlrwcpQgBTA",
        "outputId": "d88de4d5-5483-4fb8-a53f-29cd419fc8ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                         attachment_id     text  begin  end\n",
              "0           0  8f4d3be1-3a09-4d76-94ef-f8b1dbfa686b  пингвин     29  100\n",
              "1           1  4f9e3cb5-b9de-48bc-a51d-875b8fea8e10  пингвин     21   79\n",
              "2           2  1de7b5b0-ce08-419f-aeed-e7e480da953d  пингвин      7   59\n",
              "3           3  72f70640-6931-4f57-8c72-a68e48032cfb  пингвин     22   87\n",
              "4           4  6933a0f1-a0e1-48d8-91be-b445ca6c80ce  пингвин      9   64"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc7f9cd7-6015-4020-a0a7-322ab402198a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>attachment_id</th>\n",
              "      <th>text</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>8f4d3be1-3a09-4d76-94ef-f8b1dbfa686b</td>\n",
              "      <td>пингвин</td>\n",
              "      <td>29</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4f9e3cb5-b9de-48bc-a51d-875b8fea8e10</td>\n",
              "      <td>пингвин</td>\n",
              "      <td>21</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1de7b5b0-ce08-419f-aeed-e7e480da953d</td>\n",
              "      <td>пингвин</td>\n",
              "      <td>7</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>72f70640-6931-4f57-8c72-a68e48032cfb</td>\n",
              "      <td>пингвин</td>\n",
              "      <td>22</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6933a0f1-a0e1-48d8-91be-b445ca6c80ce</td>\n",
              "      <td>пингвин</td>\n",
              "      <td>9</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc7f9cd7-6015-4020-a0a7-322ab402198a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc7f9cd7-6015-4020-a0a7-322ab402198a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc7f9cd7-6015-4020-a0a7-322ab402198a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64c8c9a8-e0c7-4080-ba0d-3b68f6b1ad19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64c8c9a8-e0c7-4080-ba0d-3b68f6b1ad19')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64c8c9a8-e0c7-4080-ba0d-3b68f6b1ad19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_cnt = video_labels.groupby('text').size().to_dict()\n",
        "print(labels_cnt)\n",
        "# 75 - train, 15 - val, 10 - test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Dou_DHiTHW",
        "outputId": "557e9f00-9c40-481a-84b3-3a667c085250"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'бабочка': 20, 'бегемот': 20, 'бык': 20, 'дельфин': 20, 'динозавр': 20, 'жираф': 20, 'змея': 20, 'козел': 20, 'корова': 20, 'кролик': 20, 'курица': 20, 'лебедь': 20, 'лев': 20, 'лиса': 20, 'лось': 20, 'лягушка': 20, 'медведь': 20, 'медуза': 20, 'мышь': 20, 'обезьяна': 20, 'орел': 20, 'павлин': 20, 'паук': 20, 'пингвин': 20, 'птица': 20, 'пчела': 20, 'свинья': 20, 'слон': 20, 'собака': 20, 'тигр': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_counter = dict()\n",
        "val_counter = dict()\n",
        "train_counter = dict()\n",
        "\n",
        "for idx, row in video_labels.iterrows():\n",
        "  attachment_id = video_labels.iloc[idx]['attachment_id']\n",
        "  filename = os.path.join(video_dir, attachment_id+\".mp4\")\n",
        "  label = video_labels.iloc[idx]['text']\n",
        "  begin = video_labels.iloc[idx]['begin']\n",
        "  end = video_labels.iloc[idx]['end']\n",
        "  if label not in train_counter:\n",
        "    dataset_type = 'train'\n",
        "    train_counter[label] = 1\n",
        "  elif train_counter[label] < labels_cnt[label]*0.75:\n",
        "    dataset_type = 'train'\n",
        "    train_counter[label] += 1\n",
        "  elif label not in val_counter:\n",
        "    dataset_type = 'val'\n",
        "    val_counter[label] = 1\n",
        "  elif val_counter[label] < val_counter[label]*0.25:\n",
        "    dataset_type = 'val'\n",
        "    val_counter[label] += 1\n",
        "  elif label not in test_counter:\n",
        "    dataset_type = 'test'\n",
        "    test_counter[label] = 1\n",
        "  else:\n",
        "    dataset_type = 'test'\n",
        "    test_counter[label] += 1\n",
        "\n",
        "  base_name = os.path.join(dataset_dir , dataset_type, label, attachment_id)\n",
        "  load_video(path=filename,\n",
        "             begin=begin,\n",
        "             end=end,\n",
        "             base_name=base_name,\n",
        "             resize=(10, 10)\n",
        "             )\n"
      ],
      "metadata": {
        "id": "OTXYLF_8ijzG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "CL2gysnIwMuV",
        "outputId": "23317175-5a49-4906-a3de-749b490acc09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-71edb8cbcc24>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yjmtLh76wd2D",
        "outputId": "7ddaeee0-3a81-4576-c289-ab209ba922fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset/test/бабочка/e421d77c-1dcd-4124-b2a4-b2415569a4dd'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z+1\n",
        "https://stackoverflow.com/questions/63567352/cnn-rnn-architecture-for-video-recognition\n",
        "https://discuss.pytorch.org/t/cnn-lstm-implementation-for-video-classification/52018"
      ],
      "metadata": {
        "id": "DMtAm-mPj4Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIrdshw322FY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class BasicVideoDataset(Dataset):\n",
        "    def __init__(self, annotations_file, video_dir, IMG_SIZE, labels_list):\n",
        "        self.video_labels = pd.read_csv(annotations_file, sep='\\t')\n",
        "        self.video_dir = video_dir\n",
        "        self.IMG_SIZE = IMG_SIZE\n",
        "        self.frames_cnt = max(self.video_labels['end']-self.video_labels['begin'])\n",
        "        self.labels_list = labels_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_labels)\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename  = os.path.join(self.video_dir, self.video_labels.iloc[idx]['attachment_id']+\".mp4\")\n",
        "        label = self.video_labels.iloc[idx]['text']\n",
        "        begin = self.video_labels.iloc[idx]['begin']\n",
        "        end = self.video_labels.iloc[idx]['end']\n",
        "        frames = self.load_video(filename, begin, end, resize=(self.IMG_SIZE, self.IMG_SIZE)) # Загрузка видео!!!!\n",
        "        return frames[: self.frames_cnt], labels_list.index(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVrvMnpp5OjJ"
      },
      "source": [
        "* The __init__ function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms (covered in more detail in the next section).\n",
        "* The __len__ function returns the number of samples in our dataset.\n",
        "* The __getitem__ function loads and returns a sample from the dataset at the given index idx."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxL6umLs3sf6"
      },
      "outputs": [],
      "source": [
        "training_data = BasicVideoDataset(annotations_file, video_dir, IMG_SIZE=IMG_SIZE, labels_list=labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnSV_-Ne1546"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames, label = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "2tXhCmMqGyzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcDbpBd-MPaj",
        "outputId": "021bd0dd-c81e-41d3-a479-e9dbb2c81cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 110, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0hlodXXZFuT",
        "outputId": "3f0613b7-b296-4b6d-865a-f2e9610b3d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "EX1m2LKowAuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to be able to train our model on a hardware accelerator like the GPU or MPS, if available. Let’s check to see if torch.cuda or torch.backends.mps are available, otherwise we use the CPU."
      ],
      "metadata": {
        "id": "Nr7LRDHRv55x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "#device = \"cuda\""
      ],
      "metadata": {
        "id": "RsWcBZEhvtCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9bce62-5c0e-4383-f2eb-357b891e1ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define our neural network by subclassing nn.Module, and initialize the neural network layers in __init__. Every nn.Module subclass implements the operations on input data in the forward method."
      ],
      "metadata": {
        "id": "KHVNfZyewF4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cnn2d(nn.Module):\n",
        "    def __init__(self, IMG_SIZE=224):\n",
        "        super(cnn2d, self).__init__()\n",
        "        self.IMG_SIZE = IMG_SIZE\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=110, out_channels=50, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(50, 25, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(25, 5, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(5*28*28, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "     out = self.layer1(x)\n",
        "     out = self.layer2(out)\n",
        "     out = self.layer3(out)\n",
        "     out = out.reshape(out.size(0), -1)\n",
        "     out = self.drop_out(out)\n",
        "     out = self.fc1(out)\n",
        "     out = self.fc2(out)\n",
        "     return out\n",
        "\n",
        "     # https://neurohive.io/ru/tutorial/cnn-na-pytorch/\n"
      ],
      "metadata": {
        "id": "T9VvWB81wGiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create an instance of NeuralNetwork, and move it to the device, and print its structure."
      ],
      "metadata": {
        "id": "6bXnHS7awQLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn2d().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQqZupOIwQpW",
        "outputId": "444729a2-30f4-4b2c-a906-ebddaf5a2b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn2d(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(110, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(50, 25, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(25, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=3920, out_features=1000, bias=True)\n",
            "  (fc2): Linear(in_features=1000, out_features=30, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(BATCH_SIZE, 110, IMG_SIZE, IMG_SIZE).to(device)\n",
        "output = model(input)\n",
        "output.shape # [4, 8, 56, 56]"
      ],
      "metadata": {
        "id": "ztdewcNzFYnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec67e7c7-7934-4c19-a625-f745846bf811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "8*56*56"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AF3SsuRaIKQ",
        "outputId": "f6900801-a532-4bab-b5cb-0b63342d0403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25088"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the model, we pass it the input data. This executes the model’s forward, along with some background operations. Do not call model.forward() directly!\n",
        "\n",
        "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output. We get the prediction probabilities by passing it through an instance of the nn.Softmax module."
      ],
      "metadata": {
        "id": "m5EtY3yGw36S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение"
      ],
      "metadata": {
        "id": "ddoo_ipAXFNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn2d().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "hoSYMT2OXHO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_dataloader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for i, (frames, labels) in enumerate(train_dataloader):\n",
        "      frames = frames.to(device, dtype=torch.float)\n",
        "      labels = labels.to(device, dtype=torch.float)\n",
        "       # Прямой запуск\n",
        "      outputs = model(frames)\n",
        "      labels=labels.to(torch.int64)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "        # Отслеживание точности\n",
        "      total = labels.size(0)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct = (predicted == labels).sum().item()\n",
        "      acc_list.append(correct / total)\n",
        "\n",
        "      if (i + 1) % 10 == 0:\n",
        "          print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, NUM_EPOCHS, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ],
      "metadata": {
        "id": "CyhtVXlyYZ00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c029067-ba36-4022-dd69-2821abcffbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [10/100], Loss: 3.3898, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [20/100], Loss: 3.3922, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [30/100], Loss: 3.4089, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [40/100], Loss: 3.3941, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [50/100], Loss: 3.4020, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [60/100], Loss: 3.4209, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [70/100], Loss: 3.4279, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [80/100], Loss: 3.4350, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [90/100], Loss: 3.4053, Accuracy: 0.00%\n",
            "Epoch [1/10], Step [100/100], Loss: 3.4348, Accuracy: 0.00%\n",
            "Epoch [2/10], Step [10/100], Loss: 3.3981, Accuracy: 0.00%\n",
            "Epoch [2/10], Step [20/100], Loss: 3.4015, Accuracy: 16.67%\n",
            "Epoch [2/10], Step [30/100], Loss: 3.4158, Accuracy: 0.00%\n",
            "Epoch [2/10], Step [40/100], Loss: 3.3921, Accuracy: 0.00%\n",
            "Epoch [2/10], Step [50/100], Loss: 3.3860, Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (frames, labels) in enumerate(train_dataloader):\n",
        "      frames = frames.to(device, dtype=torch.float)\n",
        "      labels = labels.to(device, dtype=torch.float)\n",
        "      outputs = model(frames)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of the model on the 10000 test images: {} %'.format((correct / total) * 100))\n",
        "\n"
      ],
      "metadata": {
        "id": "5SEVU34dhWbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Сохраняем модель и строим график\n",
        "# torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')"
      ],
      "metadata": {
        "id": "li8mPAjQk0iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.dtype"
      ],
      "metadata": {
        "id": "Nqpefp4sk5J7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}