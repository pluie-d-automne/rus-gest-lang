{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "lnfivnf7o6t6s0nrrsdsj"
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oeehsf1r3w09rt08q90jr"
   },
   "source": [
    "# CNN RNN\n",
    "По этому примеру: https://huggingface.co/keras-io/video-classification-cnn-rnn/blob/main/main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellId": "04bwv5re0mp6mx6sxfus4q"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "izhdht7mlqiz20yx8da59"
   },
   "outputs": [],
   "source": [
    "annotations_path = 'SLOVO_DATAFRAME.tsv'\n",
    "video_path = 'animals'\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 12\n",
    "\n",
    "MAX_SEQ_LENGTH=20\n",
    "NUM_FEATURES=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "tiyxc3rvq497925odq0x25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44e8d2a0-7e01-450b-90b0-beb7400d2c1e</td>\n",
       "      <td>Ё</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>640</td>\n",
       "      <td>360</td>\n",
       "      <td>156.0</td>\n",
       "      <td>36</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df5b08f0-41d1-4572-889c-8b893e71069b</td>\n",
       "      <td>А</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>640</td>\n",
       "      <td>360</td>\n",
       "      <td>150.0</td>\n",
       "      <td>36</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17f53df4-c467-4aff-9f48-20687b63d49a</td>\n",
       "      <td>Р</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>640</td>\n",
       "      <td>360</td>\n",
       "      <td>133.0</td>\n",
       "      <td>40</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e3add916-c708-4339-ad98-7e2740be29e9</td>\n",
       "      <td>Е</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>640</td>\n",
       "      <td>360</td>\n",
       "      <td>144.0</td>\n",
       "      <td>43</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bd7272ed-1850-48f1-a2a8-c8fed523dc37</td>\n",
       "      <td>Ч</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>640</td>\n",
       "      <td>360</td>\n",
       "      <td>96.0</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          attachment_id text  ... begin  end\n",
       "0  44e8d2a0-7e01-450b-90b0-beb7400d2c1e    Ё  ...    36  112\n",
       "1  df5b08f0-41d1-4572-889c-8b893e71069b    А  ...    36   76\n",
       "2  17f53df4-c467-4aff-9f48-20687b63d49a    Р  ...    40   97\n",
       "3  e3add916-c708-4339-ad98-7e2740be29e9    Е  ...    43  107\n",
       "4  bd7272ed-1850-48f1-a2a8-c8fed523dc37    Ч  ...    20   70\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_df = pd.read_csv(annotations_path, sep='\\t')\n",
    "annot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellId": "3vn74885luh8z5eryfek4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e61c12a9-f727-441d-86e8-a9b854decd3e</td>\n",
       "      <td>пингвин</td>\n",
       "      <td>32</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2eca9c1e-103c-4a23-98c8-1e994fe76762</td>\n",
       "      <td>пингвин</td>\n",
       "      <td>18</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78c4c85b-5b75-42e7-bf3b-ee323b05c573</td>\n",
       "      <td>жираф</td>\n",
       "      <td>62</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ee72ac2-cd61-4995-93eb-4e9e5a43f873</td>\n",
       "      <td>жираф</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a912411f-d2b8-46f3-9741-c326897a08c8</td>\n",
       "      <td>лягушка</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98eedd68-135e-498e-9704-3cde2655a480</td>\n",
       "      <td>лягушка</td>\n",
       "      <td>10</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2fe89f0b-eb56-4225-865d-3f55cf9059be</td>\n",
       "      <td>бегемот</td>\n",
       "      <td>28</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2e133e33-aff4-44c1-b8f0-30ae2cdb03b7</td>\n",
       "      <td>бегемот</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          attachment_id     text begin  end\n",
       "0  e61c12a9-f727-441d-86e8-a9b854decd3e  пингвин    32  111\n",
       "1  2eca9c1e-103c-4a23-98c8-1e994fe76762  пингвин    18   65\n",
       "2  78c4c85b-5b75-42e7-bf3b-ee323b05c573    жираф    62  126\n",
       "3  8ee72ac2-cd61-4995-93eb-4e9e5a43f873    жираф    15   56\n",
       "4  a912411f-d2b8-46f3-9741-c326897a08c8  лягушка     5   55\n",
       "5  98eedd68-135e-498e-9704-3cde2655a480  лягушка    10   61\n",
       "6  2fe89f0b-eb56-4225-865d-3f55cf9059be  бегемот    28  109\n",
       "7  2e133e33-aff4-44c1-b8f0-30ae2cdb03b7  бегемот    24   75"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Возьмем для начала уменьшенный датасет из 30 животных и поделим датасет на train и test\n",
    "selected_animals = [\n",
    "    'пингвин','жираф', 'лягушка', 'бегемот', 'козел',\n",
    "    'лиса', 'динозавр', 'кролик', 'собака', 'обезьяна',\n",
    "    'корова', 'свинья', 'медуза', 'курица', 'павлин',\n",
    "    'дельфин', 'слон', 'медведь', 'лебедь', 'орел',\n",
    "    'бык', 'змея', 'птица', 'лось', 'пчела',\n",
    "    'лев', 'тигр', 'мышь', 'паук', 'бабочка'\n",
    "    ]\n",
    "train_df = pd.DataFrame(columns=['attachment_id', 'text', 'begin', 'end'])\n",
    "test_df = pd.DataFrame(columns=['attachment_id', 'text', 'begin', 'end'])\n",
    "for animal in selected_animals:\n",
    "    train_df = pd.concat([train_df, annot_df[annot_df.text==animal][['attachment_id', 'text', 'begin', 'end']][:18]], ignore_index=True)\n",
    "    test_df = pd.concat([test_df, annot_df[annot_df.text==animal][['attachment_id', 'text', 'begin', 'end']][18:]], ignore_index=True)\n",
    "    \n",
    "test_df.head(8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellId": "hajs2lkcjndyy5050akb"
   },
   "outputs": [],
   "source": [
    "# The following two methods are taken from this tutorial:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, begin, end, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    frame_index=begin\n",
    "    try:\n",
    "        while True and frame_index <= end:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "            frame_index+=1\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "0kiu80ml0pfa3efv9w4h94k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 20:56:55.907382: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "lqvcg6hrcaoz6keevmiyo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['бабочка', 'бегемот', 'бык', 'дельфин', 'динозавр', 'жираф', 'змея', 'козел', 'корова', 'кролик', 'курица', 'лебедь', 'лев', 'лиса', 'лось', 'лягушка', 'медведь', 'медуза', 'мышь', 'обезьяна', 'орел', 'павлин', 'паук', 'пингвин', 'птица', 'пчела', 'свинья', 'слон', 'собака', 'тигр']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"text\"])\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellId": "w20x88om7cygemv99bqah"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (540, 20, 2048)\n",
      "Frame masks in train set: (540, 20)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"attachment_id\"].values.tolist()\n",
    "    begins = df[\"begin\"].values.tolist()\n",
    "    ends =df[\"end\"].values.tolist()\n",
    "    labels = df[\"text\"].values\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(''.join([root_dir, path, '.mp4']), begin=begins[idx], end=ends[idx])\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, video_path)\n",
    "test_data, test_labels = prepare_all_videos(test_df, video_path)\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellId": "ymrdlmlo5yrwwh2yokmbtr"
   },
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "# logdir = str(Path(os.path.join(\n",
    "#     current_dir,\n",
    "#     \"logs\",\n",
    "#     \"scalars\",\n",
    "#     datetime.now().strftime('%Y%m%d-%H%M%S'),\n",
    "# )))+'\\\\'\n",
    "logdir = f\"logs/scalars/{datetime.now().strftime('%Y%m%d-%H%M%S')}/\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "def run_experiment():\n",
    "    filepath = Path.cwd()\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[\n",
    "            checkpoint,\n",
    "            tensorboard_callback,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellId": "qr187xrytx0xi61dls4gf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.4006 - accuracy: 0.0156     \n",
      "Epoch 1: val_loss improved from inf to 3.40747, saving model to /home/jupyter/work/resources\n",
      "6/6 [==============================] - 7s 346ms/step - loss: 3.4003 - accuracy: 0.0159 - val_loss: 3.4075 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3979 - accuracy: 0.0547\n",
      "Epoch 2: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 3.3975 - accuracy: 0.0476 - val_loss: 3.4138 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3952 - accuracy: 0.0469\n",
      "Epoch 3: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 3.3948 - accuracy: 0.0476 - val_loss: 3.4200 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3925 - accuracy: 0.0508\n",
      "Epoch 4: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.3922 - accuracy: 0.0476 - val_loss: 3.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3901 - accuracy: 0.0586\n",
      "Epoch 5: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.3896 - accuracy: 0.0476 - val_loss: 3.4326 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3875 - accuracy: 0.0547\n",
      "Epoch 6: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 3.3871 - accuracy: 0.0476 - val_loss: 3.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3850 - accuracy: 0.0430\n",
      "Epoch 7: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 3.3845 - accuracy: 0.0476 - val_loss: 3.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3823 - accuracy: 0.0469\n",
      "Epoch 8: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 3.3820 - accuracy: 0.0476 - val_loss: 3.4513 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3800 - accuracy: 0.0508\n",
      "Epoch 9: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 3.3795 - accuracy: 0.0476 - val_loss: 3.4576 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3773 - accuracy: 0.0469\n",
      "Epoch 10: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 3.3770 - accuracy: 0.0476 - val_loss: 3.4639 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3750 - accuracy: 0.0469\n",
      "Epoch 11: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 3.3745 - accuracy: 0.0476 - val_loss: 3.4701 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/12\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3723 - accuracy: 0.0508\n",
      "Epoch 12: val_loss did not improve from 3.40747\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 3.3721 - accuracy: 0.0476 - val_loss: 3.4764 - val_accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.4012 - accuracy: 0.0333\n",
      "Test accuracy: 3.33%\n"
     ]
    }
   ],
   "source": [
    "history, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cellId": "bh8qm22gizc1lsnfpldk9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: animals/5c6dd45e-9224-4527-94fb-ca36308f46ba.mp4\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "  слон:  3.35%\n",
      "  бегемот:  3.35%\n",
      "  бык:  3.35%\n",
      "  медуза:  3.35%\n",
      "  корова:  3.35%\n",
      "  козел:  3.35%\n",
      "  свинья:  3.35%\n",
      "  кролик:  3.35%\n",
      "  лебедь:  3.35%\n",
      "  медведь:  3.35%\n",
      "  дельфин:  3.35%\n",
      "  орел:  3.34%\n",
      "  жираф:  3.34%\n",
      "  пингвин:  3.34%\n",
      "  динозавр:  3.34%\n",
      "  лиса:  3.34%\n",
      "  лягушка:  3.34%\n",
      "  обезьяна:  3.33%\n",
      "  курица:  3.33%\n",
      "  павлин:  3.33%\n",
      "  собака:  3.32%\n",
      "  змея:  3.31%\n",
      "  тигр:  3.31%\n",
      "  лось:  3.31%\n",
      "  лев:  3.31%\n",
      "  мышь:  3.31%\n",
      "  паук:  3.31%\n",
      "  птица:  3.31%\n",
      "  пчела:  3.31%\n",
      "  бабочка:  3.31%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path, begin, end):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path), begin, end)\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "\n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
    "    return embed.embed_file(\"animation.gif\")\n",
    "\n",
    "\n",
    "test_video = np.random.choice(test_df[\"attachment_id\"].values.tolist())\n",
    "begin = int(test_df[test_df.attachment_id==test_video]['begin'])\n",
    "end = int(test_df[test_df.attachment_id==test_video]['end'])\n",
    "test_video_path = f\"animals/{test_video}.mp4\"\n",
    "print(f\"Test video path: {test_video_path}\")\n",
    "test_frames = sequence_prediction(test_video_path, begin, end)\n",
    "#to_gif(test_frames[:MAX_SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cellId": "kvb7d7pzmghue5lptpq0j"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5c6dd45e-9224-4527-94fb-ca36308f46ba</td>\n",
       "      <td>лиса</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           attachment_id  text begin end\n",
       "11  5c6dd45e-9224-4527-94fb-ca36308f46ba  лиса    20  54"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.attachment_id=='5c6dd45e-9224-4527-94fb-ca36308f46ba']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "notebookId": "96afdf4f-0c2c-4665-ba43-f9038b83894c",
  "notebookPath": "5_CNN_RNN_Slovo.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
